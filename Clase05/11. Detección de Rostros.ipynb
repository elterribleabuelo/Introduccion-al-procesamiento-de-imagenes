{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11. Detección de Rostros.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"HCe0ZF-IBaFx"},"source":["from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","\n","import random\n","from ipywidgets import interact, interactive, fixed, interact_manual\n","import numpy as np\n","from PIL import Image\n","import io\n","import cv2\n","import matplotlib.image as mpimg\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GzOrZZBi4bzP"},"source":["def VideoCapture():\n","  js = Javascript('''\n","    async function create(){\n","      div = document.createElement('div');\n","      document.body.appendChild(div);\n"," \n","      video = document.createElement('video');\n","      video.setAttribute('playsinline', '');\n"," \n","      div.appendChild(video);\n"," \n","      stream = await navigator.mediaDevices.getUserMedia({video: {facingMode: \"environment\"}});\n","      video.srcObject = stream;\n"," \n","      await video.play();\n"," \n","      canvas =  document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n"," \n","      div_out = document.createElement('div');\n","      document.body.appendChild(div_out);\n","      img = document.createElement('img');\n","      div_out.appendChild(img);\n","    }\n"," \n","    async function capture(){\n","        return await new Promise(function(resolve, reject){\n","            pendingResolve = resolve;\n","            canvas.getContext('2d').drawImage(video, 0, 0);\n","            result = canvas.toDataURL('image/jpeg', 0.8);\n","            pendingResolve(result);\n","        })\n","    }\n"," \n","    function showimg(imgb64){\n","        img.src = \"data:image/jpg;base64,\" + imgb64;\n","    }\n"," \n","  ''')\n","  display(js)\n"," \n","def byte2image(byte):\n","  jpeg = b64decode(byte.split(',')[1])\n","  im = Image.open(io.BytesIO(jpeg))\n","  return np.array(im)\n"," \n","def image2byte(image):\n","  image = Image.fromarray(image)\n","  buffer = io.BytesIO()\n","  image.save(buffer, 'jpeg')\n","  buffer.seek(0)\n","  x = b64encode(buffer.read()).decode('utf-8')\n","  return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DZX4YlzY4eUk"},"source":["VideoCapture()\n","eval_js('create()')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p0fo0E6aUS1w"},"source":["# 1. Deteccion de rostros"]},{"cell_type":"code","metadata":{"id":"42fcDqxYoccQ","executionInfo":{"status":"ok","timestamp":1604870264434,"user_tz":300,"elapsed":26922,"user":{"displayName":"Renzo Guerrero Huayta","photoUrl":"","userId":"09470644507167265769"}},"outputId":"97d8e333-99e3-4bb1-a2a3-6a5ee7d0f656","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XLCrlJ3UZ6d5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7lLRGuClZ6-r"},"source":["os.chdir(\"/content/drive/My Drive/Intro_procesamiento_de_imagenes/Data\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X7_etBZo62ek"},"source":["VideoCapture()\n","eval_js('create()')\n","face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n","\n","while True:\n","  byte = eval_js('capture()')\n","  im = byte2image(byte)\n","  print(im.shape)\n","  gray = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n","  faces = face_detector.detectMultiScale(gray, scaleFactor = 1.1, 4) # de que tanto tamaño va ser la cara a detectar\n","  print(faces)\n","  print(\"hola\")\n","  for (x, y, w, h) in faces:\n","    #x,y: posiciones\n","    # w:ancho\n","    cv2.rectangle(im, (x,y), (x+w,y+h), (255,0,0), 2) # grosor de 2 pixeles\n","\n","  eval_js('showimg(\"{}\")'.format(image2byte(im)))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CXa_JRDuuqnf"},"source":["plt.imshow(im[x:x+w,y:y+h])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3wjR9B-cvq8W"},"source":["## 1.1 Difuminacion de rostro"]},{"cell_type":"code","metadata":{"id":"dV0sLXa3wNMg"},"source":["VideoCapture()\n","eval_js('create()')\n","face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n"," \n","while True:\n","  byte = eval_js('capture()')\n","  im = byte2image(byte)\n","  gray = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n","  faces = face_detector.detectMultiScale(gray, 1.1, 4)\n","  zero = np.zeros(im.shape)\n","\n","\n","  for (x, y, w, h) in faces:\n","    kernel = np.ones((50,50),np.float32)/2500\n","    im[y:y+h,x:x+w] = cv2.filter2D(im[y:y+h,x:x+w],-1,kernel) # aplicamos el filtro a la cara detectada\n","\n","  eval_js('showimg(\"{}\")'.format(image2byte(im)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wl5Mn9yVxrm7"},"source":["# haarcascade usa la imagen integral"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ubG8P8GHw0Ul"},"source":["## 1.2 Recortar la cara"]},{"cell_type":"code","metadata":{"id":"Lt0XmAumw35-"},"source":["VideoCapture()\n","eval_js('create()')\n","face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n"," \n","while True:\n","  byte = eval_js('capture()')\n","  im = byte2image(byte)\n","  gray = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n","  faces = face_detector.detectMultiScale(gray, 1.1, 4) # te da el x,y,w,h de la cara \n","  \n","  for (x, y, w, h) in faces:\n","    a = np.ones((h,w))\n","    #a =im[y:y+h,x:x+w]\n","\n","  eval_js('showimg(\"{}\")'.format(image2byte(im[y:y+h,x:x+w])))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"90uvryh2x9T1"},"source":["## 1.3 Ejercicio 3 ( 10 min - 1 punto )"]},{"cell_type":"markdown","metadata":{"id":"SvTVSDaz2o-w"},"source":["Reemplazar la cara por una imagen RGB"]},{"cell_type":"code","metadata":{"id":"tQSdBpSwyJDG"},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mcF5ESWPyS3R"},"source":["img = mpimg.imread('cafe.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_eOs8_HyA4m"},"source":["# Tarea 4: Donde detecte la cara , se debe superponer una imagen cualquiera, la persona al moverse\n","# delante de la camara , la imagen q la tape tambien se de mover con ella."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TVCiFfclG2tt"},"source":["# 2. Deteccion de ojos"]},{"cell_type":"code","metadata":{"id":"QKHAUriBWgvP"},"source":["VideoCapture()\n","eval_js('create()')\n","eye_detector = cv2.CascadeClassifier('haarcascade_eye.xml')\n"," \n","while True:\n","  byte = eval_js('capture()')\n","  im = byte2image(byte)\n","  gray = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n","  eyes = eye_detector.detectMultiScale(gray, 1.1, 4)\n","  \n","  for (x, y, w, h) in eyes:\n","    cv2.rectangle(im, (x,y), (x+w,y+h), (255,0,0), 2)\n","\n","  eval_js('showimg(\"{}\")'.format(image2byte(im)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-R-mx26znup"},"source":["# Tarea 5\n","# Solamente detectar los ojos de la cara que esta en frente a la camara "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5BcHXtzY24Sa"},"source":["# Tarea 6\n","# Hacer un detector de asteriscos\n","# Sacar valor medio de cada una de las filas y columnas\n","# edwinml148@gmail.com"],"execution_count":null,"outputs":[]}]}